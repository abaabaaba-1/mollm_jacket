exper_name: "circle_packing"
description: "n = 32 in unit square"
save_dir: "/home/hp/src/mollm_results/circle_packing"
save_suffix: "circle_packing_32"
resume: False

model:
  name: zgca,gemini-2.5-flash-nothinking  #,gemini-2.5-flash-nothinking     gpt-4-0125-preview  gpt-4o-2024-05-13
  # name2: zgca,gpt-4o-2024-05-13
  prompt_module: Prompt
  experience_prob: 0.5
  crossover_prob: 0.8
  mutation_prob: 0.2 
  explore_prob: 0. 
use_au: False  # If True, this will use au model, set to false if you only want to use one LLM
n_circles: 32

goals: [radii]
optimization_direction: [max]
prompt_info_path: /home/hp/src/MOLLM/problem/circle_n/prompt_info.yaml
### Important ###
evalutor_path: problem.circle_n.evaluator

optimization: 
  pop_size: 50
  eval_budget: 2500

early_stopping: False

